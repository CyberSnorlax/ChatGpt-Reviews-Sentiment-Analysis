{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e1a8756-952b-45d8-a24d-001f426e1863",
   "metadata": {
    "id": "2e1a8756-952b-45d8-a24d-001f426e1863",
    "outputId": "a9769d34-3469-40fb-ddce-859ff20726a9",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>comment</th>\n",
       "      <th>score</th>\n",
       "      <th>date_time</th>\n",
       "      <th>appVersion</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>Score_Sentiment</th>\n",
       "      <th>tokens</th>\n",
       "      <th>cleaned_tokens</th>\n",
       "      <th>Text_Sentiment</th>\n",
       "      <th>Emoji_Sentiment</th>\n",
       "      <th>Overall_Sentiment</th>\n",
       "      <th>Comment_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>764bde06-e9d2-4211-97a2-f4f64bcf907d</td>\n",
       "      <td>M A saad</td>\n",
       "      <td>very active</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-11-18 13:31:58</td>\n",
       "      <td>1.2024.310</td>\n",
       "      <td>2024-11-18</td>\n",
       "      <td>13:31:58</td>\n",
       "      <td>Positive score</td>\n",
       "      <td>['very', 'active']</td>\n",
       "      <td>['very', 'active']</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.25, 'pos': 0.75, 'compou...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.25, 'pos': 0.75, 'compou...</td>\n",
       "      <td>Positive Sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36788635-5d48-4a4e-abdd-7fadffc07ac1</td>\n",
       "      <td>Sudip Sarkar</td>\n",
       "      <td>very nice app ðŸ¥°</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-11-18 13:31:31</td>\n",
       "      <td>1.2024.268</td>\n",
       "      <td>2024-11-18</td>\n",
       "      <td>13:31:31</td>\n",
       "      <td>Positive score</td>\n",
       "      <td>['very', 'nice', 'app', 'ðŸ¥°']</td>\n",
       "      <td>['very', 'nice', 'app', 'ðŸ¥°']</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.393, 'pos': 0.607, 'comp...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.291, 'pos': 0.709, 'comp...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.319, 'pos': 0.681, 'comp...</td>\n",
       "      <td>Positive Sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74a2c5ec-2bdb-4784-ab8a-90224d65d981</td>\n",
       "      <td>Sehlule Moyo</td>\n",
       "      <td>good app</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-11-18 13:31:05</td>\n",
       "      <td>1.2024.268</td>\n",
       "      <td>2024-11-18</td>\n",
       "      <td>13:31:05</td>\n",
       "      <td>Positive score</td>\n",
       "      <td>['good', 'app']</td>\n",
       "      <td>['good', 'app']</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.256, 'pos': 0.744, 'comp...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.256, 'pos': 0.744, 'comp...</td>\n",
       "      <td>Positive Sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0f7a206b-4a5c-4b67-ad59-54e4d3cefe01</td>\n",
       "      <td>Preethi Preru</td>\n",
       "      <td>very good</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-11-18 13:29:14</td>\n",
       "      <td>1.2024.310</td>\n",
       "      <td>2024-11-18</td>\n",
       "      <td>13:29:14</td>\n",
       "      <td>Positive score</td>\n",
       "      <td>['very', 'good']</td>\n",
       "      <td>['very', 'good']</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.238, 'pos': 0.762, 'comp...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.238, 'pos': 0.762, 'comp...</td>\n",
       "      <td>Positive Sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e8f1438a-3734-4213-9884-aa33a9b79672</td>\n",
       "      <td>Fayzan Vhora</td>\n",
       "      <td>this is nice app for student</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-11-18 13:27:53</td>\n",
       "      <td>1.2024.310</td>\n",
       "      <td>2024-11-18</td>\n",
       "      <td>13:27:53</td>\n",
       "      <td>Neutral score</td>\n",
       "      <td>['this', 'is', 'nice', 'app', 'for', 'student']</td>\n",
       "      <td>['nice', 'app', 'student']</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'comp...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'comp...</td>\n",
       "      <td>Positive Sentiment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               reviewId       userName  \\\n",
       "0  764bde06-e9d2-4211-97a2-f4f64bcf907d       M A saad   \n",
       "1  36788635-5d48-4a4e-abdd-7fadffc07ac1   Sudip Sarkar   \n",
       "2  74a2c5ec-2bdb-4784-ab8a-90224d65d981   Sehlule Moyo   \n",
       "3  0f7a206b-4a5c-4b67-ad59-54e4d3cefe01  Preethi Preru   \n",
       "4  e8f1438a-3734-4213-9884-aa33a9b79672   Fayzan Vhora   \n",
       "\n",
       "                        comment  score            date_time  appVersion  \\\n",
       "0                   very active      5  2024-11-18 13:31:58  1.2024.310   \n",
       "1               very nice app ðŸ¥°      5  2024-11-18 13:31:31  1.2024.268   \n",
       "2                      good app      4  2024-11-18 13:31:05  1.2024.268   \n",
       "3                     very good      5  2024-11-18 13:29:14  1.2024.310   \n",
       "4  this is nice app for student      3  2024-11-18 13:27:53  1.2024.310   \n",
       "\n",
       "         date      time Score_Sentiment  \\\n",
       "0  2024-11-18  13:31:58  Positive score   \n",
       "1  2024-11-18  13:31:31  Positive score   \n",
       "2  2024-11-18  13:31:05  Positive score   \n",
       "3  2024-11-18  13:29:14  Positive score   \n",
       "4  2024-11-18  13:27:53   Neutral score   \n",
       "\n",
       "                                            tokens  \\\n",
       "0                               ['very', 'active']   \n",
       "1                     ['very', 'nice', 'app', 'ðŸ¥°']   \n",
       "2                                  ['good', 'app']   \n",
       "3                                 ['very', 'good']   \n",
       "4  ['this', 'is', 'nice', 'app', 'for', 'student']   \n",
       "\n",
       "                 cleaned_tokens  \\\n",
       "0            ['very', 'active']   \n",
       "1  ['very', 'nice', 'app', 'ðŸ¥°']   \n",
       "2               ['good', 'app']   \n",
       "3              ['very', 'good']   \n",
       "4    ['nice', 'app', 'student']   \n",
       "\n",
       "                                      Text_Sentiment  \\\n",
       "0  {'neg': 0.0, 'neu': 0.25, 'pos': 0.75, 'compou...   \n",
       "1  {'neg': 0.0, 'neu': 0.393, 'pos': 0.607, 'comp...   \n",
       "2  {'neg': 0.0, 'neu': 0.256, 'pos': 0.744, 'comp...   \n",
       "3  {'neg': 0.0, 'neu': 0.238, 'pos': 0.762, 'comp...   \n",
       "4  {'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'comp...   \n",
       "\n",
       "                                     Emoji_Sentiment  \\\n",
       "0  {'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...   \n",
       "1  {'neg': 0.0, 'neu': 0.291, 'pos': 0.709, 'comp...   \n",
       "2  {'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...   \n",
       "3  {'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...   \n",
       "4  {'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound...   \n",
       "\n",
       "                                   Overall_Sentiment   Comment_Sentiment  \n",
       "0  {'neg': 0.0, 'neu': 0.25, 'pos': 0.75, 'compou...  Positive Sentiment  \n",
       "1  {'neg': 0.0, 'neu': 0.319, 'pos': 0.681, 'comp...  Positive Sentiment  \n",
       "2  {'neg': 0.0, 'neu': 0.256, 'pos': 0.744, 'comp...  Positive Sentiment  \n",
       "3  {'neg': 0.0, 'neu': 0.238, 'pos': 0.762, 'comp...  Positive Sentiment  \n",
       "4  {'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'comp...  Positive Sentiment  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "file_path = '/Users/williamsempire/Desktop/Columbia/Courses/5067 NLP/FinalProj/cleaned_gpt_reviews.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5c3e6f0-b6cc-475a-9b98-3324a8123f6f",
   "metadata": {
    "id": "c5c3e6f0-b6cc-475a-9b98-3324a8123f6f",
    "outputId": "3154a73d-d8c9-4a91-dc88-0697a132d363",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/williamsempire/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/var/folders/g5/rh17cc010_75svb2l5rt9bcw0000gn/T/ipykernel_61494/991293889.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  before_comments['cleaned_comment'] = before_comments['comment'].apply(clean_text)\n",
      "/var/folders/g5/rh17cc010_75svb2l5rt9bcw0000gn/T/ipykernel_61494/991293889.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after_comments['cleaned_comment'] = after_comments['comment'].apply(clean_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High frequency keywords before version:\n",
      "[('app', 17683), ('good', 11272), ('best', 5578), ('chatgpt', 4267), ('ai', 4262), ('great', 4231), ('nice', 3808), ('like', 3688), ('helpful', 3385), ('amazing', 3205), ('love', 2848), ('really', 2827), ('use', 2670), ('chat', 2364), ('useful', 2198), ('gpt', 1885), ('awesome', 1813), ('information', 1667), ('excellent', 1614), ('much', 1571)]\n",
      "\n",
      "High frequency bigrams before version:\n",
      "['ai app' 'amazing app' 'app good' 'app really' 'best ai' 'best app'\n",
      " 'chat gpt' 'easy use' 'excellent app' 'good app' 'great app'\n",
      " 'helpful app' 'love app' 'nice app' 'really good' 'really helpful'\n",
      " 'use app' 'useful app' 'voice chat' 'web version']\n",
      "\n",
      "High frequency keywords after version:\n",
      "[('app', 50028), ('good', 45545), ('best', 18642), ('nice', 16198), ('helpful', 12575), ('great', 11500), ('ai', 9212), ('amazing', 8215), ('chatgpt', 8062), ('like', 8023), ('useful', 7987), ('love', 7227), ('use', 7025), ('excellent', 6875), ('really', 6829), ('chat', 5324), ('awesome', 4763), ('help', 4608), ('gpt', 4550), ('work', 4304)]\n",
      "\n",
      "High frequency bigrams after version:\n",
      "['ai app' 'amazing app' 'app good' 'app helpful' 'app really' 'app useful'\n",
      " 'best ai' 'best app' 'chat gpt' 'easy use' 'excellent app' 'good app'\n",
      " 'great app' 'helpful app' 'like app' 'love app' 'nice app' 'really good'\n",
      " 'really helpful' 'useful app']\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "target_version = '1.2024.061'\n",
    "\n",
    "before_comments = data[data['appVersion'] < target_version]\n",
    "before_comments['cleaned_comment'] = before_comments['comment'].apply(clean_text)\n",
    "\n",
    "after_comments = data[data['appVersion'] > target_version]\n",
    "after_comments['cleaned_comment'] = after_comments['comment'].apply(clean_text)\n",
    "\n",
    "def analyze_keywords_and_bigrams(comments):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = comments['cleaned_comment'].dropna().apply(lambda x: [word for word in x.split() if word not in stop_words])\n",
    "    token_list = list(chain.from_iterable(tokens))\n",
    "    token_counts = Counter(token_list).most_common(20)\n",
    "    vectorizer = CountVectorizer(ngram_range=(2, 2), max_features=20, stop_words='english')\n",
    "    ngram_matrix = vectorizer.fit_transform(comments['cleaned_comment'].dropna())\n",
    "    ngram_features = vectorizer.get_feature_names_out()\n",
    "\n",
    "    return token_counts, ngram_features\n",
    "\n",
    "before_token_counts, before_bigrams = analyze_keywords_and_bigrams(before_comments)\n",
    "after_token_counts, after_bigrams = analyze_keywords_and_bigrams(after_comments)\n",
    "\n",
    "print(\"High frequency keywords before version:\")\n",
    "print(before_token_counts)\n",
    "print(\"\\nHigh frequency bigrams before version:\")\n",
    "print(before_bigrams)\n",
    "\n",
    "print(\"\\nHigh frequency keywords after version:\")\n",
    "print(after_token_counts)\n",
    "print(\"\\nHigh frequency bigrams after version:\")\n",
    "print(after_bigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cc9067-b896-4544-a0c7-d02b08478705",
   "metadata": {
    "id": "b1cc9067-b896-4544-a0c7-d02b08478705",
    "outputId": "b30cdd7d-3b03-4680-8e1e-9a439808e7da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing negative comments before version 1.2024.061...\n",
      "High-frequency keywords before version 1.2024.061:\n",
      "[('app', 1267), ('cant', 415), ('good', 383), ('wrong', 342), ('chatgpt', 325), ('use', 308), ('ai', 291), ('problem', 288), ('time', 285), ('error', 278), ('like', 278), ('even', 275), ('doesnt', 264), ('chat', 262), ('dont', 255), ('bad', 237), ('answer', 225), ('im', 215), ('information', 215), ('gpt', 202)]\n",
      "\n",
      "High-frequency bigrams before version 1.2024.061:\n",
      "[('chat gpt', 99), ('phone number', 68), ('web version', 64), ('good app', 52), ('doesnt work', 51), ('dont know', 50), ('went wrong', 47), ('wrong answer', 46), ('wrong answers', 45), ('try later', 43), ('gives wrong', 42), ('app good', 37), ('use app', 37), ('worst app', 36), ('voice chat', 34), ('error message', 33), ('bad app', 32), ('wont let', 32), ('error occurred', 31), ('app doesnt', 30)]\n",
      "\n",
      "Processing negative comments after version 1.2024.061...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lixiaoyang\\AppData\\Local\\Temp\\ipykernel_24312\\4178913896.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comments['cleaned_comment'] = comments['comment'].apply(clean_text)\n",
      "C:\\Users\\Lixiaoyang\\AppData\\Local\\Temp\\ipykernel_24312\\4178913896.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comments['cleaned_comment'] = comments['comment'].apply(clean_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-frequency keywords after version 1.2024.061:\n",
      "[('app', 3309), ('good', 1241), ('wrong', 1071), ('cant', 931), ('bad', 893), ('ai', 850), ('chatgpt', 844), ('problem', 815), ('use', 805), ('error', 777), ('dont', 774), ('time', 755), ('answer', 753), ('even', 752), ('chat', 736), ('like', 647), ('doesnt', 643), ('sometimes', 609), ('working', 590), ('give', 537)]\n",
      "\n",
      "High-frequency bigrams after version 1.2024.061:\n",
      "[('chat gpt', 287), ('try later', 192), ('wrong answer', 160), ('gives wrong', 156), ('wrong answers', 144), ('bad app', 133), ('doesnt work', 131), ('dont know', 131), ('good app', 127), ('worst app', 123), ('stopped working', 121), ('wrong information', 117), ('error occurred', 104), ('went wrong', 103), ('use app', 102), ('network error', 94), ('dont like', 85), ('app doesnt', 75), ('keeps saying', 73), ('app good', 72)]\n"
     ]
    }
   ],
   "source": [
    "specific_version = '1.2024.061'\n",
    "\n",
    "negative_comments = data[data['Comment_Sentiment'] == 'Negative Sentiment']\n",
    "\n",
    "before_version = negative_comments[negative_comments['appVersion'] < specific_version]\n",
    "after_version = negative_comments[negative_comments['appVersion'] > specific_version]\n",
    "\n",
    "def process_comments(comments, label):\n",
    "    print(f\"\\nProcessing negative comments {label} version {specific_version}...\")\n",
    "    comments['cleaned_comment'] = comments['comment'].apply(clean_text)\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = comments['cleaned_comment'].dropna().apply(lambda x: [word for word in x.split() if word not in stop_words])\n",
    "\n",
    "    token_list = list(chain.from_iterable(tokens))\n",
    "    token_counts = Counter(token_list).most_common(20)\n",
    "\n",
    "    print(f\"High-frequency keywords {label} version {specific_version}:\")\n",
    "    print(token_counts)\n",
    "\n",
    "    vectorizer = CountVectorizer(ngram_range=(2, 2), max_features=20, stop_words='english')\n",
    "    ngram_matrix = vectorizer.fit_transform(comments['cleaned_comment'].dropna())\n",
    "    ngram_features = vectorizer.get_feature_names_out()\n",
    "    ngram_counts = Counter(dict(zip(ngram_features, ngram_matrix.toarray().sum(axis=0)))).most_common(20)\n",
    "\n",
    "    print(f\"\\nHigh-frequency bigrams {label} version {specific_version}:\")\n",
    "    print(ngram_counts)\n",
    "\n",
    "process_comments(before_version, \"before\")\n",
    "process_comments(after_version, \"after\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5e06ad-8d0f-42ee-8814-920e98aed564",
   "metadata": {
    "id": "fc5e06ad-8d0f-42ee-8814-920e98aed564"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
